"""
    for i in range(d):
        for j in range(d):
            # cov (xi, xj) = E[x_i*x_j] - E[x_i]E[x_j]
            # E[x_j] = mu[j],  E[x_i] = mu[i] avg value of a feature
            Eij = np.sum(matrix[:,(i+1)] * matrix[:,(j+1)]) / r
            #if (j == 2):
                #print(matrix[:,(i+1)], "\n", matrix[:,(j+1)], "\n", matrix[:,(i+1)] * matrix[:,(j+1)], "\n", np.sum(matrix[:,(i+1)] * matrix[:,(j+1)]))
            sigma[i,j] = Eij - mu[i] * mu[j]
    return mu,np.add(sigma, (c) * np.identity(d))
"""

def naive_bayes_classifier(class_priors, train_0, train_1, test):

    y_tag = np.zeros(test.shape[0])
    train_dps = [train_0.shape[0], train_1.shape[0]]

    """
    for each data point in the TEST data:
        for each class label:
            (1) calculate P(X=x|Y) by multiplying the count of each feature taking some value in the TRAIN set (+1 for smoothing)
                given class label, divided by total number of TRAIN data points
            (2) multipy by class prior (using TRAIN set)
        (3) take argmax of these probs to return predicted label
    """

    for r in range(test.shape[0]):
        probs = np.zeros(2)
        counts = np.ones(0)
        test_point = test[r,:]
        """if (r==0):
            print(test_point)"""
        for d in range(1, test_point.shape[0]):
            """if (r == 0):
                print(test_point[d])"""
            for y in range(2):
                if (y == 0):
                    counts[y] += np.log((train_0[:,d] == test_point[d]).sum() + 1)
                    """if (r == 0):
                        print(train_0[:,d], (train_0[:,d] == test_point[d]).sum())
                        print("counts[y]:", counts[y])"""
                if (y == 1):
                    counts[y] += np.log((train_1[:, d] == test_point[d]).sum() + 1)
                if (d == test_point.shape[0] - 1):
                    probs[y] = np.log((1 / train_dps[y])) + np.log(counts[y]) + np.log(class_priors[y])
                    """if (r == 0):
                        print(counts[y], probs[y])"""
        y_tag[r] = np.argmax(probs)

    return y_tag


code to test norm:
a = np.arange(0,27,3).reshape(3,3)
print(a)
print(norm(a))

"""
print("df_test_0:\n", df_train_0)
print("df_test_1:\n", df_train_1)
#print(df_test.loc[:,"race"])
"""


$$\mathbbm{P}_{a1}(\hat{Y}=\hat{y}) = \mathbbm{P}_{a2}(\hat{Y}=\hat{y}) = .... = \mathbbm{P}_{ai}(\hat{Y}=\hat{y})
\iff \mathbbm{P}
(\hat{Y}=\hat{y})=\mathbbm{P}_{ai}(\hat{Y}=\hat{y})$$
$$\forall a_i \in \mathbbm{N}, \forall \hat{y} \in \hat{Y}$$